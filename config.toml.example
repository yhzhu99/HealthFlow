# HealthFlow Configuration

# Select the active LLM provider for agent reasoning and evaluation
active_llm = "deepseek-v3"

# LLM Provider Configurations
# All agents and the shared LLMTaskEvaluator use the same provider for consistency

[llm.openai]
base_url = "https://api.openai.com/v1"
api_key = "YOUR_OPENAI_API_KEY"
model_name = "gpt-4-turbo-preview"

[llm.deepseek-v3]
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_DEEPSEEK_API_KEY"
model_name = "deepseek-chat"

[llm.deepseek-r1]
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_DEEPSEEK_API_KEY"
model_name = "deepseek-reasoner"

# Data Storage Configuration for Self-Evolution
[data]
data_dir = "./data"                    # Root data directory
memory_dir = "./data/memory"           # Stores experiences and evolving prompts
tools_dir = "./data/tools"             # Stores dynamically created tool code
evolution_dir = "./data/evolution"     # Stores evolution data

# Agent System Configuration
[agent]
max_iterations = 10      # Maximum iterations per task execution
tool_timeout = 120       # Tool execution timeout in seconds
max_react_rounds = 8     # Maximum ReAct rounds for complex tasks

# Evaluation Configuration for Self-Evolution Loop
[evaluation]
success_threshold = 6.0              # Lowered threshold to encourage evolution
evaluation_timeout = 180             # LLM evaluation timeout in seconds
store_evaluation_traces = true       # Store detailed traces for research and evolution

# Evolution Configuration (NEW SECTION)
[evolution]
evolution_trigger_score = 6.0        # Score below which evolution is triggered
evolution_frequency_tasks = 3        # Evolve every N tasks regardless of score

# Logging Configuration
[logging]
log_level = "INFO"                   # INFO, DEBUG, WARNING, ERROR
log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
log_file = "./healthflow.log"