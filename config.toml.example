# HealthFlow Configuration

# Select the active LLM provider for agent reasoning and evaluation
active_llm = "deepseek-v3"

# LLM Provider Configurations
# All agents and the shared LLMTaskEvaluator use the same provider for consistency

[llm.openai]
base_url = "https://api.openai.com/v1"
api_key = "YOUR_OPENAI_API_KEY"
model_name = "gpt-4-turbo-preview"

[llm.deepseek-v3]
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_DEEPSEEK_API_KEY"
model_name = "deepseek-chat"

[llm.deepseek-r1]
base_url = "https://api.deepseek.com/v1"
api_key = "YOUR_DEEPSEEK_API_KEY"
model_name = "deepseek-reasoner"

# Data Storage Configuration for Self-Evolution
[data]
data_dir = "./data"                    # Root data directory
memory_dir = "./data/memory"           # Stores experiences and evolving prompts
tools_dir = "./data/tools"             # Stores dynamically created tool code
evaluation_dir = "./data/evaluation"   # Stores evaluation traces and feedback

# Agent System Configuration
[agent]
max_iterations = 10      # Maximum iterations per task execution
tool_timeout = 120       # Tool execution timeout in seconds

# Evaluation Configuration for Self-Evolution Loop
[evaluation]
success_threshold = 7.5              # Overall score threshold for task success
evaluation_timeout = 180             # LLM evaluation timeout in seconds
store_evaluation_traces = true       # Store detailed traces for research and evolution

# Logging Configuration
[logging]
log_level = "INFO"                   # INFO, DEBUG, WARNING, ERROR
log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
log_file = "./healthflow.log"
